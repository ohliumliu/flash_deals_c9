{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"jdbc:mysql://localhost:3306/flashdeals\"\n",
    "properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read a table from database.\n",
    "\n",
    "products_df = sqlContext.read.format(\"jdbc\").options(\n",
    "url = url,\n",
    "driver=\"com.mysql.jdbc.Driver\",\n",
    "dbtable=\"products\",\n",
    "user=\"root\",\n",
    "password=\"\"\n",
    ").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('name', 'string'),\n",
       " ('description', 'string'),\n",
       " ('created_at', 'timestamp'),\n",
       " ('updated_at', 'timestamp'),\n",
       " ('detail_page_url', 'string'),\n",
       " ('manufacturer', 'string'),\n",
       " ('list_price', 'int'),\n",
       " ('title', 'string'),\n",
       " ('small_image_url', 'string'),\n",
       " ('medium_image_url', 'string'),\n",
       " ('price', 'int'),\n",
       " ('amount_saved', 'int'),\n",
       " ('percentage_saved', 'int'),\n",
       " ('is_supersaver_shipping', 'boolean'),\n",
       " ('is_prime', 'boolean'),\n",
       " ('ASIN', 'string'),\n",
       " ('merchant_id', 'int'),\n",
       " ('catalog_id', 'int'),\n",
       " ('dealer_id', 'int')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|  id|catalog_id|\n",
      "+----+----------+\n",
      "|2245|        19|\n",
      "|2246|        19|\n",
      "|2247|        19|\n",
      "|2248|        19|\n",
      "|2249|        19|\n",
      "|2250|        19|\n",
      "|2251|        19|\n",
      "|2252|        19|\n",
      "|2253|        19|\n",
      "|2264|        19|\n",
      "+----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# simple operation\n",
    "categories_df = products_df.select([\"id\", \"catalog_id\"])\n",
    "categories_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way to read. see readme for pyspark options for this to work.\n",
    "products_df = sqlContext.read.jdbc(url = url, table=\"products\", properties=properties)\n",
    "products_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bf7447c291a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save categories_df as a new table in db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcategories_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categories\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"append\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'categories_df' is not defined"
     ]
    }
   ],
   "source": [
    "# save categories_df as a new table in db\n",
    "categories_df.write.jdbc(url=url, table=\"categories\", mode = \"append\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pipeline\n",
    "\n",
    "* Tokenizer of lower case\n",
    "* StopWordsRemover\n",
    "* HashingTF\n",
    "* IDF\n",
    "* Normalizer\n",
    "* kmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               title|         title_words|\n",
      "+--------------------+--------------------+\n",
      "|InnoGear® 100ml A...|[innogear®, 100ml...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"title_words\")\n",
    "words_df = tokenizer.transform(products_df)\n",
    "words_df.select([\"title\", \"title_words\"]).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|title                                                                                                                                                                                              |title_words                                                                                                                                                                                                                    |title_words_filtered                                                                                                                                                                                           |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|InnoGear® 100ml Aromatherapy Essential Oil Diffuser Portable Ultrasonic Cool Mist Aroma Humidifier with Color LED Lights Changing and Waterless Auto Shut-off Function for Home Office Bedroom Room|[innogear®, 100ml, aromatherapy, essential, oil, diffuser, portable, ultrasonic, cool, mist, aroma, humidifier, with, color, led, lights, changing, and, waterless, auto, shut-off, function, for, home, office, bedroom, room]|[innogear®, 100ml, aromatherapy, essential, oil, diffuser, portable, ultrasonic, cool, mist, aroma, humidifier, color, led, lights, changing, waterless, auto, shut-off, function, home, office, bedroom, room]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "stopwords = StopWordsRemover(inputCol=\"title_words\", outputCol=\"title_words_filtered\")\n",
    "words_filter_df = stopwords.transform(words_df)\n",
    "words_filter_df.select([\"title\", \"title_words\", \"title_words_filtered\"]).show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HashingTF and IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|title_tf                                                                    |title_tf_idf                                                                                                                                                                                                                                    |\n",
      "+----------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(16,[0,2,3,4,5,6,7,8,9,14,15],[2.0,1.0,4.0,1.0,1.0,4.0,1.0,3.0,1.0,2.0,4.0])|(16,[0,2,3,4,5,6,7,8,9,14,15],[1.6112503279732713,0.7591051483517427,3.036420593406971,0.5920510636885765,0.7591051483517427,2.6883750854484516,0.7591051483517427,1.7761531910657296,0.9057086225436182,1.7088306563121352,1.6646415888996493])|\n",
      "|(16,[1,4,5,8,9,11,12,13,15],[1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0])          |(16,[1,4,5,8,9,11,12,13,15],[0.7591051483517427,0.5920510636885765,0.7591051483517427,0.5920510636885765,0.9057086225436182,0.5179430915348546,1.9195516876277878,1.0169342576538425,0.4161603972249123])                                       |\n",
      "|(16,[1,6,9,12,13,14],[2.0,1.0,2.0,1.0,1.0,1.0])                             |(16,[1,6,9,12,13,14],[1.5182102967034854,0.6720937713621129,1.8114172450872363,0.9597758438138939,1.0169342576538425,0.8544153281560676])                                                                                                       |\n",
      "+----------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, CountVectorizer\n",
    "\n",
    "tf = HashingTF(inputCol=\"title_words_filtered\", outputCol=\"title_tf\", numFeatures=16)\n",
    "words_filter_tf_df = tf.transform(words_filter_df)\n",
    "words_filter_tf_df.count()\n",
    "\n",
    "# Can also use CountVectorizer which allows easier inspection of the bag of words.\n",
    "\n",
    "idf = IDF(inputCol=\"title_tf\", outputCol=\"title_tf_idf\")\n",
    "words_filter_tf_idf_df = idf.fit(words_filter_tf_df).transform(words_filter_tf_df)\n",
    "words_filter_tf_idf_df.select([\"title_tf\", \"title_tf_idf\"]).show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|title_tf_idf                                                                                                                                                                                                                                    |title_tf_idf_norm                                                                                                                                                                                                                                    |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(16,[0,2,3,4,5,6,7,8,9,14,15],[1.6112503279732713,0.7591051483517427,3.036420593406971,0.5920510636885765,0.7591051483517427,2.6883750854484516,0.7591051483517427,1.7761531910657296,0.9057086225436182,1.7088306563121352,1.6646415888996493])|(16,[0,2,3,4,5,6,7,8,9,14,15],[0.290380209052455,0.1368062478214934,0.5472249912859736,0.10669969070533472,0.1368062478214934,0.48450008404707856,0.1368062478214934,0.32009907211600414,0.16322718735185246,0.30796617670162124,0.3000024044619525])|\n",
      "|(16,[1,4,5,8,9,11,12,13,15],[0.7591051483517427,0.5920510636885765,0.7591051483517427,0.5920510636885765,0.9057086225436182,0.5179430915348546,1.9195516876277878,1.0169342576538425,0.4161603972249123])                                       |(16,[1,4,5,8,9,11,12,13,15],[0.27121058739629395,0.211526054197141,0.27121058739629395,0.211526054197141,0.32358859383749433,0.18504900197031826,0.6858111051801886,0.36332692244357584,0.14868441615435446])                                        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"title_tf_idf\", outputCol=\"title_tf_idf_norm\")\n",
    "words_filter_tf_idf_normalize_df = normalizer.transform(words_filter_tf_idf_df)\n",
    "words_filter_tf_idf_normalize_df.select([\"title_tf_idf\", \"title_tf_idf_norm\"]).show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   avg(prediction)|\n",
      "+------------------+\n",
      "|0.3076923076923077|\n",
      "|              0.65|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"title_tf_idf_norm\", k=2, seed=20)\n",
    "model = kmeans.fit(words_filter_tf_idf_normalize_df)\n",
    "words_kmeans_df = model.transform(words_filter_tf_idf_normalize_df)\n",
    "words_kmeans_df.groupBy('catalog_id').avg().select(\"avg(prediction)\").show(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|catalog_id|prediction|\n",
      "+----------+----------+\n",
      "|        19|         0|\n",
      "|        19|         1|\n",
      "|        19|         1|\n",
      "|        19|         0|\n",
      "|        19|         1|\n",
      "|        19|         1|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        21|         0|\n",
      "|        21|         1|\n",
      "|        21|         0|\n",
      "|        21|         0|\n",
      "|        21|         1|\n",
      "|        21|         1|\n",
      "|        21|         1|\n",
      "|        21|         0|\n",
      "|        21|         1|\n",
      "|        21|         0|\n",
      "|        19|         0|\n",
      "|        21|         1|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        21|         1|\n",
      "|        21|         0|\n",
      "|        19|         1|\n",
      "|        21|         0|\n",
      "|        19|         1|\n",
      "|        21|         1|\n",
      "|        19|         0|\n",
      "|        19|         1|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        21|         1|\n",
      "|        21|         1|\n",
      "|        21|         1|\n",
      "|        21|         1|\n",
      "|        19|         0|\n",
      "|        19|         1|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        19|         0|\n",
      "|        21|         1|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_kmeans_df.select([\"catalog_id\", \"prediction\"]).show(46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the whole process in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "\n",
    "step = 0 \n",
    "\n",
    "step += 1\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=str(step) + \"_tokenizer\")\n",
    "\n",
    "step += 1\n",
    "stopwords = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=str(step) + \"_stopwords\")\n",
    "\n",
    "step += 1\n",
    "tf = HashingTF(inputCol=stopwords.getOutputCol(), outputCol=str(step) + \"_tf\", numFeatures=16)\n",
    "\n",
    "step += 1\n",
    "idf = IDF(inputCol=tf.getOutputCol(), outputCol=str(step) + \"_idf\")\n",
    "\n",
    "step += 1\n",
    "normalizer = Normalizer(inputCol=idf.getOutputCol(), outputCol=str(step) + \"_normalizer\")\n",
    "\n",
    "step += 1\n",
    "kmeans = KMeans(featuresCol=normalizer.getOutputCol(), predictionCol = str(step) + \"_kmeans\", k=2, seed=20)\n",
    "\n",
    "kmeans_pipeline = Pipeline(stages=[tokenizer, stopwords, tf, idf, normalizer, kmeans])\n",
    "\n",
    "model = kmeans_pipeline.fit(products_df)\n",
    "words_prediction = model.transform(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|6_kmeans|\n",
      "+--------+\n",
      "|       0|\n",
      "|       1|\n",
      "|       1|\n",
      "|       0|\n",
      "|       1|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_prediction.select(\"6_kmeans\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to write the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = \"title\"\n",
    "stages=[Tokenizer(), StopWordsRemover(), HashingTF(numFeatures=16), IDF(),\n",
    "                                   Normalizer(), KMeans(k = 2, seed = 20)]\n",
    "stages[0].setInputCol(feature)\n",
    "stages[0].setOutputCol(\"1_\"+stages[0].__class__.__name__)\n",
    "\n",
    "for (i, s) in enumerate(stages[1:-1]):\n",
    "    i = i + 1\n",
    "    s.setInputCol(stages[i-1].getOutputCol())\n",
    "    s.setOutputCol(str(i+1)+\"_\"+s.__class__.__name__)\n",
    "\n",
    "stages[-1].setFeaturesCol(stages[-2].getOutputCol())\n",
    "stages[-1].setPredictionCol(str(len(stages)) + \"_\" + stages[-1].__class__.__name__)\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "model = pipeline.fit(products_df)\n",
    "prediction = model.transform(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|     avg(6_KMeans)|\n",
      "+------------------+\n",
      "|0.3076923076923077|\n",
      "|              0.65|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.groupBy('catalog_id').avg().select(\"avg(\" + stages[-1].getPredictionCol() + \")\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
